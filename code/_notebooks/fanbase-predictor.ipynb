{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: code-post\n",
    "title: Pedicting rooting interests on reddit\n",
    "description: Going to see if we can predict neutral fan rooting interests from reddit posts.\n",
    "tags: [neural nets]\n",
    "---\n",
    "\n",
    "In this notebook / post I'm going to try to see if we can predict who a\n",
    "supposedly neutral fan is rooting for in the (as of this writing) about to\n",
    "end Lakers-Heat NBA finals. To do this, I'm going to attempt to scrape posts\n",
    "from game threads by Heat and Lakers fans to train an LSTM based model. As long\n",
    "as I can scrape the flair from from the reddit API, this should be doable. If\n",
    "not, then I will have to scrape from the team specific subreddits and try that\n",
    "way.\n",
    "\n",
    "Outline:\n",
    "- Accessing Reddit\n",
    "  - Reddit's API\n",
    "  - Getting posts\n",
    "- Making a dataset\n",
    "  - Encoding posts\n",
    "  - Saving the data\n",
    "- Training a model\n",
    "- Test set predictions\n",
    "\n",
    "## Accessing reddit\n",
    "\n",
    "If you don't know what [reddit](https://reddit.com/) is, it's a website that is\n",
    "organized into communities called _subreddits_. The site has _users_ which belong to\n",
    "multiple subreddits. Each subreddit contains a sequence of _posts_ which can be links\n",
    "to other sites, images, or text. Each post contains _comments_ which are text only\n",
    "an are made by the users. The _comment section_ is organized as a forest of trees\n",
    "wich top level comments and then comments nested below each top level comment. Each\n",
    "user can have a _flair_ which varies with the subreddit they are posting in. The\n",
    "flair and username are posted along with each comment. The flair will contains a\n",
    "small image as well as text. Not every user has a flair associated to it for every\n",
    "subreddit to which they belong. It is not always required to be a member of the\n",
    "subreddit in order to post, although this varies by community.\n",
    "\n",
    "We will be using the NBA subreddit which as of this writing has ~3.5 million users.\n",
    "Users in this subreddit have flairs which denote which team the user is a supporter\n",
    "of. Mine is for the Cleveland Cavaliers.\n",
    "\n",
    "In order to access reddit, we need to have a reddit account and then create an application\n",
    "with that account as a developer of the application. Go to [the apps page](https://www.reddit.com/prefs/apps)\n",
    "to create an application. You need to store the name of the app as the `user_agent`, the\n",
    "`client_id` is the 14 character string that is below the app name once it's created, \n",
    "you'll have a 27 character secret secret that is generated and is the `client_secret`, \n",
    "and you'll need your `username`. I have put these credentials in an encrypted YAML file\n",
    "that I created using ansible-vault.\n",
    "\n",
    "We will be using [PRAW](https://github.com/praw-dev/praw), the Python Reddit API\n",
    "Wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import yaml\n",
    "from ansible_vault import Vault\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault = Vault(getpass())\n",
    "with open('redditcreds.yml', 'r') as f:\n",
    "    \n",
    "\n",
    "reddit = praw.Reddit(username=reddit_creds['username'],\n",
    "                     user_agent=reddit_creds['user_agent'],\n",
    "                     client_id=reddit_creds['client_id'],\n",
    "                     client_secret=reddit_creds['client_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swiggityswooty111: Pooh and Piglet kitten edition\n"
     ]
    }
   ],
   "source": [
    "# We'll default with /r/awww\n",
    "subreddit = \"awww\"\n",
    "\n",
    "# This turns creates a subreddit object\n",
    "# then pull the top 5 best submissions at the time it was pulled\n",
    "# then stores them in a list\n",
    "top_5 = list(reddit.subreddit(subreddit).top(limit=5,time_filter='day'))\n",
    "\n",
    "post = top_5[2]\n",
    "\n",
    "print(str(post.author) + \":\", post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gitpage] *",
   "language": "python",
   "name": "conda-env-gitpage-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
