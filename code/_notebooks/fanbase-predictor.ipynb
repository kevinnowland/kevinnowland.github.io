{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: code-post\n",
    "title: Pedicting rooting interests on reddit\n",
    "description: Going to see if we can predict neutral fan rooting interests from reddit posts.\n",
    "tags: [neural nets]\n",
    "---\n",
    "\n",
    "In this notebook / post I'm going to try to see if we can predict who a\n",
    "supposedly neutral fan is rooting for in the (as of this writing) about to\n",
    "end Lakers-Heat NBA finals. To do this, I'm going to attempt to scrape posts\n",
    "from game threads by Heat and Lakers fans to train an LSTM based model. As long\n",
    "as I can scrape the flair from from the reddit API, this should be doable. If\n",
    "not, then I will have to scrape from the team specific subreddits and try that\n",
    "way.\n",
    "\n",
    "Outline:\n",
    "- Accessing Reddit\n",
    "  - Reddit's API\n",
    "  - Getting posts\n",
    "- Making a dataset\n",
    "  - Encoding posts\n",
    "  - Saving the data\n",
    "- Training a model\n",
    "- Test set predictions\n",
    "\n",
    "## Accessing reddit\n",
    "\n",
    "If you don't know what [reddit](https://reddit.com/) is, it's a website that is\n",
    "organized into communities called _subreddits_. The site has _users_ which belong to\n",
    "multiple subreddits. Each subreddit contains a sequence of _submissions_ (also called\n",
    "_posts_) which can be links\n",
    "to other sites, images, or text. Each post contains _comments_ which are text only\n",
    "an are made by the users. The _comment section_ is organized as a forest of trees\n",
    "wich top level comments and then comments nested below each top level comment. Each\n",
    "user can have a _flair_ which varies with the subreddit they are posting in. The\n",
    "flair and username are posted along with each comment. The flair will contains a\n",
    "small image as well as text. Not every user has a flair associated to it for every\n",
    "subreddit to which they belong. It is not always required to be a member of the\n",
    "subreddit in order to post, although this varies by community.\n",
    "\n",
    "We will be using the NBA subreddit which as of this writing has ~3.5 million users.\n",
    "Users in this subreddit have flairs which denote which team the user is a supporter\n",
    "of. Mine is for the Cleveland Cavaliers.\n",
    "\n",
    "In order to access reddit, we need to have a reddit account and then create an application\n",
    "with that account as a developer of the application. Go to [the apps page](https://www.reddit.com/prefs/apps)\n",
    "to create an application. (Please read the terms and conditions!)\n",
    "You need to store the name of the app as the `user_agent`, the\n",
    "`client_id` is the 14 character string that is below the app name once it's created, \n",
    "you'll have a 27 character secret secret that is generated and is the `client_secret`, \n",
    "and you'll need your `username`. I have put these credentials in an encrypted YAML file\n",
    "that I created using ansible-vault.\n",
    "\n",
    "We will be using [PRAW](https://github.com/praw-dev/praw), the Python Reddit API\n",
    "Wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import yaml\n",
    "from ansible_vault import Vault\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ····················\n"
     ]
    }
   ],
   "source": [
    "vault = Vault(getpass())\n",
    "with open('redditcreds.yml', 'r') as f:\n",
    "    reddit_creds = vault.load(f.read())\n",
    "\n",
    "reddit = praw.Reddit(username=reddit_creds['username'],\n",
    "                     user_agent=reddit_creds['user_agent'],\n",
    "                     client_id=reddit_creds['client_id'],\n",
    "                     client_secret=reddit_creds['client_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get into the [NBA subreddit](https://www.reddit.com/r/nba) and search for posts which are _game threads_\n",
    "to which users will post while a game is ongoing. These are posted automatically and so they have a \n",
    "predictible title format which makes searching for them and then filtering the received submisisons\n",
    "by title easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('nba')\n",
    "\n",
    "submissions = subreddit.search(query='title:\"GAME THREAD\"',\n",
    "                               time_filter=\"month\")\n",
    "game_threads = [\n",
    "    s for s in submissions \n",
    "    if\n",
    "        s.title[:11] == 'GAME THREAD' \n",
    "        and (\"Lakers\" in s.title or \"Heat\" in s.title)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME THREAD: Miami Heat (44-29) @ Los Angeles Lakers (52-19) - (October 09, 2020)\n",
      "GAME THREAD: Miami Heat (44-29) @ Los Angeles Lakers (52-19) - (September 30, 2020)\n",
      "GAME THREAD: Los Angeles Lakers (52-19) @ Miami Heat (44-29) - (October 06, 2020)\n",
      "GAME THREAD: Los Angeles Lakers (52-19) @ Miami Heat (44-29) - (October 04, 2020)\n",
      "GAME THREAD: Miami Heat (44-29) @ Los Angeles Lakers (52-19) - (October 02, 2020)\n",
      "GAME THREAD: Denver Nuggets (46-27) @ Los Angeles Lakers (52-19) - (September 26, 2020)\n",
      "GAME THREAD: Los Angeles Lakers (52-19) @ Denver Nuggets (46-27) - (September 24, 2020)\n",
      "GAME THREAD: Los Angeles Lakers (52-19) @ Denver Nuggets (46-27) - (September 22, 2020)\n",
      "GAME THREAD: Denver Nuggets (46-27) @ Los Angeles Lakers (52-19) - (September 18, 2020)\n",
      "GAME THREAD: Boston Celtics (48-24) @ Miami Heat (44-29) - (September 27, 2020)\n",
      "GAME THREAD: Denver Nuggets (46-27) @ Los Angeles Lakers (52-19) - (September 20, 2020)\n",
      "GAME THREAD: Miami Heat (44-29) @ Boston Celtics (48-24) - (September 25, 2020)\n",
      "GAME THREAD: Boston Celtics (48-24) @ Miami Heat (44-29) - (September 23, 2020)\n",
      "GAME THREAD: Miami Heat (44-29) @ Boston Celtics (48-24) - (September 15, 2020)\n",
      "GAME THREAD: Miami Heat (44-29) @ Boston Celtics (48-24) - (September 17, 2020)\n",
      "GAME THREAD: Boston Celtics (48-24) @ Miami Heat (44-29) - (September 19, 2020)\n",
      "GAME THREAD: Houston Rockets (44-28) @ Los Angeles Lakers (52-19) - (September 12, 2020)\n",
      "GAME THREAD: Los Angeles Lakers (52-19) @ Houston Rockets (44-28) - (September 10, 2020)\n"
     ]
    }
   ],
   "source": [
    "for t in game_threads:\n",
    "    print(t.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comments for a submission are contained in PRAW `CommentForest`. If we do not\n",
    "care about the structure, we can flatten this to a list. Note that the list\n",
    "will contain both `Comment` objects as well as `MoreComments` objectcs. It is possible to replace\n",
    "the `MoreComments` objects using the `replace_more` function, but each replacement\n",
    "requires calling the reddit API. By default, 32 of the `MoreComments` objects will\n",
    "be replaced, which I will keep but I will also limit to those which contain at least\n",
    "5 more comments in them. Doing this removes all `MoreComments` instances from\n",
    "the list of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME THREAD: Miami Heat (44-29) @ Los Angeles Lakers (52-19) - (October 09, 2020)\n",
      "number of comments: 28455\n"
     ]
    }
   ],
   "source": [
    "game_thread = game_threads[0]\n",
    "print(game_thread.title)\n",
    "print(\"number of comments:\", game_thread.num_comments)\n",
    "game_thread.comments.replace_more(limit=32, threshold=5)\n",
    "comments = game_thread.comments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a random comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment author:    StoneColdAM\n",
      "comment score:     28 (28-0)\n",
      "author flair text: Lakers\n",
      "body:\n",
      "\n",
      " Dwight Howard strategy: get Jimmy Butler ejected.\n"
     ]
    }
   ],
   "source": [
    "c = comments[10]\n",
    "print('comment author:   ', c.author.name)\n",
    "print('comment score:    ', c.score, '({}-{})'.format(c.ups, c.downs))\n",
    "print('author flair text:', c.author_flair_text)\n",
    "print('body:\\n\\n', c.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training set, the goal will be to find authors which are flaired as Lakers or Heat or have\n",
    "flair text that contains LAL or MIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of comments by Lakers users: 1042\n",
      "number of comments by Heat users  : 275\n"
     ]
    }
   ],
   "source": [
    "lakers_comments = [\n",
    "    c for c in comments\n",
    "    if\n",
    "        c.author_flair_text is not None\n",
    "        and (\n",
    "            c.author_flair_text == 'Lakers'\n",
    "            or '[LAL]' in c.author_flair_text\n",
    "        )\n",
    "]\n",
    "print('number of comments by Lakers users:', len(lakers_comments))\n",
    "\n",
    "heat_comments = [\n",
    "    c for c in comments\n",
    "    if\n",
    "        c.author_flair_text is not None\n",
    "        and (\n",
    "            c.author_flair_text == 'Heat'\n",
    "            or '[MIA]' in c.author_flair_text\n",
    "        )\n",
    "]\n",
    "print('number of comments by Heat users  :', len(heat_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of how to get comments for a given fanbase during game threads,\n",
    "let's try to build up a collection of comments and then clean up the body of those\n",
    "comments using some common NLP techniques. For example, we will require comments to \n",
    "have some minimum number of words in them, we will then remove stopwords and spaces\n",
    "and other weird text as best we can. Then we will vectorize each word. To do all this\n",
    "we will rely on `spaCy`, which I wrote about in [this post](https://kevinnowland.com/code/2020/10/04/nlp-intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacey\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gitpage] *",
   "language": "python",
   "name": "conda-env-gitpage-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
